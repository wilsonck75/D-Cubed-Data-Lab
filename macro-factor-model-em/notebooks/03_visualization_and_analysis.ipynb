{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9355982d",
   "metadata": {},
   "source": [
    "# üìà 03 ‚Äì Advanced Visualizations & Rolling Analysis\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook extends the factor modeling analysis with **time-varying** perspectives and **advanced visualizations**:\n",
    "\n",
    "1. **Rolling Window Analysis**: Examine how model fit (R¬≤) changes over time\n",
    "2. **Dynamic Factor Sensitivity**: Track evolving relationships between EM and macro factors  \n",
    "3. **Interactive Visualizations**: Generate comprehensive charts for all EM indices\n",
    "4. **Reusable Functions**: Modular code for reproducible analysis\n",
    "\n",
    "### Key Features:\n",
    "- **Rolling R¬≤ Analysis**: 60-day rolling window regression models\n",
    "- **Time-Series Visualization**: Dynamic model performance tracking\n",
    "- **Batch Processing**: Automated chart generation for all EM indices\n",
    "- **Export Functionality**: Save all visualizations to output folder\n",
    "\n",
    "### Use Cases:\n",
    "- **Risk Management**: Identify periods of high/low factor sensitivity\n",
    "- **Portfolio Analysis**: Understand when diversification benefits change\n",
    "- **Market Timing**: Spot regime changes in EM-macro relationships"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e00feb",
   "metadata": {},
   "source": [
    "## üì¶ Import Required Libraries\n",
    "\n",
    "Loading libraries for advanced analysis and visualization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73efde6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Machine learning components  \n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set plotting style for professional appearance\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (10, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c729a11f",
   "metadata": {},
   "source": [
    "## üìÅ Data Loading & Preparation\n",
    "\n",
    "Load the dataset and prepare variables for rolling analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6c7e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the combined dataset\n",
    "df = pd.read_csv('../data/combined_em_macro_data.csv', parse_dates=['date'], index_col='date')\n",
    "\n",
    "# Convert to log returns\n",
    "log_returns = np.log(df / df.shift(1)).dropna()\n",
    "\n",
    "# Separate EM and macro variables\n",
    "em_cols = [c for c in df.columns if c.startswith(('Brazil', 'India', 'China', 'SouthAfrica', 'Mexico', 'Indonesia'))]\n",
    "macro_cols = [c for c in df.columns if c not in em_cols]\n",
    "\n",
    "Y_all = log_returns[em_cols]    # EM equity returns\n",
    "X_all = log_returns[macro_cols] # Macro factor returns\n",
    "\n",
    "print(f\"üìä Dataset loaded for rolling analysis:\")\n",
    "print(f\"   ‚Ä¢ Time period: {df.index.min()} to {df.index.max()}\")\n",
    "print(f\"   ‚Ä¢ Total observations: {len(log_returns)}\")\n",
    "print(f\"   ‚Ä¢ EM indices: {len(em_cols)}\")\n",
    "print(f\"   ‚Ä¢ Macro factors: {len(macro_cols)}\")\n",
    "\n",
    "print(f\"\\nüåè EM Indices: {em_cols}\")\n",
    "print(f\"üìà Macro Factors: {macro_cols}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ef66bd",
   "metadata": {},
   "source": [
    "## üîÑ Rolling Window Analysis Function\n",
    "\n",
    "Create a reusable function to perform rolling window PCA-regression analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adcfe1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_r2_scores(X, Y, window=60, n_components=3):\n",
    "    \"\"\"\n",
    "    Calculate rolling R¬≤ scores for EM indices using PCA-based factor models.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    X : pd.DataFrame\n",
    "        Macro factor returns (independent variables)\n",
    "    Y : pd.DataFrame  \n",
    "        EM equity returns (dependent variables)\n",
    "    window : int\n",
    "        Rolling window size in days (default: 60)\n",
    "    n_components : int\n",
    "        Number of principal components to use (default: 3)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        Rolling R¬≤ scores for each EM index\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize results DataFrame\n",
    "    results = pd.DataFrame(index=Y.index[window:], columns=Y.columns)\n",
    "    \n",
    "    print(f\"üîÑ Computing rolling R¬≤ with {window}-day windows...\")\n",
    "    print(f\"   ‚Ä¢ Total windows: {len(Y) - window + 1}\")\n",
    "    print(f\"   ‚Ä¢ PCA components: {n_components}\")\n",
    "    \n",
    "    # Loop through each EM index\n",
    "    for col_idx, col in enumerate(Y.columns):\n",
    "        print(f\"   ‚Ä¢ Processing {col} ({col_idx + 1}/{len(Y.columns)})\")\n",
    "        \n",
    "        # Loop through time windows\n",
    "        for i in range(window, len(Y)):\n",
    "            # Extract window data\n",
    "            X_window = X.iloc[i - window:i]\n",
    "            Y_window = Y[col].iloc[i - window:i]\n",
    "            \n",
    "            try:\n",
    "                # Standardize macro factors\n",
    "                scaler = StandardScaler()\n",
    "                X_scaled = scaler.fit_transform(X_window)\n",
    "                \n",
    "                # Apply PCA\n",
    "                pca = PCA(n_components=n_components)\n",
    "                X_pca = pca.fit_transform(X_scaled)\n",
    "                \n",
    "                # Fit regression model\n",
    "                model = LinearRegression().fit(X_pca, Y_window)\n",
    "                \n",
    "                # Store R¬≤ score\n",
    "                results.at[Y_window.index[-1], col] = model.score(X_pca, Y_window)\n",
    "                \n",
    "            except Exception as e:\n",
    "                # Handle potential numerical issues\n",
    "                results.at[Y_window.index[-1], col] = np.nan\n",
    "    \n",
    "    print(\"‚úÖ Rolling analysis complete!\")\n",
    "    return results.astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571fe90c",
   "metadata": {},
   "source": [
    "## üìä Execute Rolling Analysis\n",
    "\n",
    "Run the rolling window analysis to track model performance over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd29d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute rolling analysis with 60-day windows\n",
    "window_size = 60\n",
    "rolling_r2 = rolling_r2_scores(X_all, Y_all, window=window_size)\n",
    "\n",
    "print(f\"\\nüìà Rolling R¬≤ Analysis Results:\")\n",
    "print(f\"   ‚Ä¢ Window size: {window_size} trading days\")\n",
    "print(f\"   ‚Ä¢ Analysis period: {rolling_r2.index.min()} to {rolling_r2.index.max()}\")\n",
    "print(f\"   ‚Ä¢ Total observations: {len(rolling_r2)}\")\n",
    "\n",
    "# Summary statistics\n",
    "print(f\"\\nüìä Rolling R¬≤ Summary Statistics:\")\n",
    "summary_stats = rolling_r2.describe()\n",
    "print(summary_stats.round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb1c864",
   "metadata": {},
   "source": [
    "## üìà Visualization & Export\n",
    "\n",
    "Generate and save rolling R¬≤ charts for all EM indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df336f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directory\n",
    "output_dir = \"../output/plots\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "print(f\"üìä Generating rolling R¬≤ visualizations for {len(rolling_r2.columns)} EM indices...\\n\")\n",
    "\n",
    "# Generate and save charts for each EM index\n",
    "for col in rolling_r2.columns:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # Plot rolling R¬≤\n",
    "    plt.plot(rolling_r2.index, rolling_r2[col], linewidth=2, alpha=0.8)\n",
    "    \n",
    "    # Add mean line\n",
    "    mean_r2 = rolling_r2[col].mean()\n",
    "    plt.axhline(y=mean_r2, color='red', linestyle='--', alpha=0.7, \n",
    "                label=f'Mean R¬≤ = {mean_r2:.3f}')\n",
    "    \n",
    "    # Formatting\n",
    "    plt.title(f'Rolling R¬≤: {col} vs Macro Factors ({window_size}-day PCA Model)', \n",
    "              fontsize=14, pad=20)\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('R¬≤ Score')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save plot\n",
    "    filename = f\"rolling_r2_{col.replace('/', '_').replace(' ', '_')}.png\"\n",
    "    filepath = os.path.join(output_dir, filename)\n",
    "    plt.savefig(filepath, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"‚úÖ {col}: Mean R¬≤ = {mean_r2:.3f}, Chart saved to {filename}\")\n",
    "\n",
    "# Create comprehensive summary plot\n",
    "plt.figure(figsize=(14, 8))\n",
    "for col in rolling_r2.columns:\n",
    "    plt.plot(rolling_r2.index, rolling_r2[col], label=col, linewidth=1.5, alpha=0.8)\n",
    "\n",
    "plt.title(f'Rolling R¬≤ Comparison: All EM Indices vs Macro Factors ({window_size}-day PCA Model)', \n",
    "          fontsize=14, pad=20)\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('R¬≤ Score')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save summary plot\n",
    "summary_filename = \"rolling_r2_all_indices_comparison.png\"\n",
    "summary_filepath = os.path.join(output_dir, summary_filename)\n",
    "plt.savefig(summary_filepath, dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nüíæ All visualizations saved to: {output_dir}\")\n",
    "print(f\"üìä Summary chart: {summary_filename}\")\n",
    "print(f\"üéØ Rolling analysis complete for {len(rolling_r2.columns)} EM indices!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b302ed",
   "metadata": {},
   "source": [
    "# Yearly Analysis: Factor Sensitivity Evolution\n",
    "\n",
    "## Overview\n",
    "In this section, we examine how factor sensitivities evolved across three distinct yearly periods:\n",
    "- **2022/2023**: Post-pandemic recovery period with elevated inflation concerns\n",
    "- **2023/2024**: Central bank tightening cycle and geopolitical tensions\n",
    "- **2024/2025**: Current period with rate normalization expectations\n",
    "\n",
    "This temporal analysis helps identify:\n",
    "1. **Structural Changes**: How macro-EM relationships evolved over time\n",
    "2. **Regime Shifts**: Periods where factor loadings significantly changed\n",
    "3. **Investment Implications**: How factor strategies performed across different market environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03db40d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate yearly R¬≤ scores for trend analysis\n",
    "yearly_periods = {\n",
    "    '2022/2023': ('2022-01-01', '2023-12-31'),\n",
    "    '2023/2024': ('2023-01-01', '2024-12-31'),\n",
    "    '2024/2025': ('2024-01-01', '2025-12-31')\n",
    "}\n",
    "\n",
    "yearly_r2_results = {}\n",
    "\n",
    "# Load the combined dataset if not already loaded\n",
    "try:\n",
    "    data = df  # Use the df from previous cell\n",
    "except NameError:\n",
    "    data = pd.read_csv('../data/combined_em_macro_data.csv', parse_dates=['date'], index_col='date')\n",
    "\n",
    "# Define column names based on the dataset structure\n",
    "em_etf_columns = em_cols  # Use the em_cols from data loading section\n",
    "macro_factor_columns = macro_cols  # Use the macro_cols from data loading section\n",
    "\n",
    "for period_name, (start_date, end_date) in yearly_periods.items():\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Period: {period_name}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    # Filter data for the period\n",
    "    period_mask = (data.index >= start_date) & (data.index <= end_date)\n",
    "    period_data = data[period_mask]\n",
    "    \n",
    "    if len(period_data) < 50:  # Minimum data requirement\n",
    "        print(f\"Insufficient data for {period_name}: {len(period_data)} observations\")\n",
    "        continue\n",
    "    \n",
    "    # Calculate log returns for this period\n",
    "    period_log_returns = np.log(period_data / period_data.shift(1)).dropna()\n",
    "    \n",
    "    # Separate EM ETFs and macro factors for this period\n",
    "    em_etfs_period = period_log_returns[em_etf_columns]\n",
    "    macro_factors_period = period_log_returns[macro_factor_columns]\n",
    "    \n",
    "    period_r2_scores = {}\n",
    "    \n",
    "    # Calculate R¬≤ for each ETF in this period\n",
    "    for etf in em_etf_columns:\n",
    "        etf_returns = em_etfs_period[etf].dropna()\n",
    "        \n",
    "        # Align macro factors with ETF data\n",
    "        common_dates = etf_returns.index.intersection(macro_factors_period.index)\n",
    "        if len(common_dates) < 30:\n",
    "            continue\n",
    "            \n",
    "        X_period = macro_factors_period.loc[common_dates]\n",
    "        y_period = etf_returns.loc[common_dates]\n",
    "        \n",
    "        # Standardize and apply PCA to macro factors\n",
    "        scaler_period = StandardScaler()\n",
    "        X_scaled_period = scaler_period.fit_transform(X_period.fillna(0))\n",
    "        \n",
    "        pca_period = PCA(n_components=3)\n",
    "        X_pca_period = pca_period.fit_transform(X_scaled_period)\n",
    "        \n",
    "        # Fit linear regression\n",
    "        model_period = LinearRegression()\n",
    "        model_period.fit(X_pca_period, y_period)\n",
    "        \n",
    "        # Calculate R¬≤\n",
    "        r2_period = model_period.score(X_pca_period, y_period)\n",
    "        period_r2_scores[etf] = r2_period\n",
    "        \n",
    "        print(f\"{etf}: R¬≤ = {r2_period:.3f}\")\n",
    "    \n",
    "    yearly_r2_results[period_name] = period_r2_scores\n",
    "\n",
    "# Create comprehensive yearly comparison visualizations\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "fig.suptitle('Yearly Factor Sensitivity Evolution Analysis (2022-2025)', fontsize=16, fontweight='bold')\n",
    "\n",
    "# 1. R¬≤ Evolution Line Chart\n",
    "ax1 = axes[0, 0]\n",
    "for etf in em_etf_columns:\n",
    "    r2_values = []\n",
    "    periods = []\n",
    "    for period in yearly_r2_results.keys():\n",
    "        if etf in yearly_r2_results[period]:\n",
    "            r2_values.append(yearly_r2_results[period][etf])\n",
    "            periods.append(period)\n",
    "    \n",
    "    if r2_values:\n",
    "        ax1.plot(periods, r2_values, marker='o', linewidth=2, label=etf, markersize=8)\n",
    "\n",
    "ax1.set_title('R¬≤ Score Evolution Across Annual Periods', fontsize=12, fontweight='bold')\n",
    "ax1.set_ylabel('R¬≤ Score')\n",
    "ax1.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 2. Yearly R¬≤ Heatmap\n",
    "ax2 = axes[0, 1]\n",
    "yearly_df = pd.DataFrame(yearly_r2_results).T\n",
    "if not yearly_df.empty:\n",
    "    sns.heatmap(yearly_df, annot=True, fmt='.3f', cmap='RdYlBu_r', \n",
    "                ax=ax2, cbar_kws={'label': 'R¬≤ Score'})\n",
    "ax2.set_title('Annual Period R¬≤ Heatmap', fontsize=12, fontweight='bold')\n",
    "ax2.set_xlabel('EM ETFs')\n",
    "ax2.set_ylabel('Time Periods')\n",
    "\n",
    "# 3. R¬≤ Range Analysis (Temporal Volatility)\n",
    "ax3 = axes[1, 0]\n",
    "etf_ranges = {}\n",
    "for etf in em_etf_columns:\n",
    "    etf_r2_values = []\n",
    "    for period_data in yearly_r2_results.values():\n",
    "        if etf in period_data:\n",
    "            etf_r2_values.append(period_data[etf])\n",
    "    \n",
    "    if len(etf_r2_values) > 1:\n",
    "        etf_ranges[etf] = max(etf_r2_values) - min(etf_r2_values)\n",
    "\n",
    "if etf_ranges:\n",
    "    etfs = list(etf_ranges.keys())\n",
    "    ranges = list(etf_ranges.values())\n",
    "    bars = ax3.bar(etfs, ranges, color='skyblue', alpha=0.7)\n",
    "    ax3.set_title('R¬≤ Temporal Volatility Across Periods', fontsize=12, fontweight='bold')\n",
    "    ax3.set_ylabel('R¬≤ Range (Max - Min)')\n",
    "    ax3.tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for bar, value in zip(bars, ranges):\n",
    "        ax3.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
    "                f'{value:.3f}', ha='center', va='bottom')\n",
    "\n",
    "# 4. Period Comparison Statistics\n",
    "ax4 = axes[1, 1]\n",
    "period_avg_r2 = {}\n",
    "for period, r2_dict in yearly_r2_results.items():\n",
    "    if r2_dict:\n",
    "        period_avg_r2[period] = np.mean(list(r2_dict.values()))\n",
    "\n",
    "if period_avg_r2:\n",
    "    periods = list(period_avg_r2.keys())\n",
    "    avg_r2 = list(period_avg_r2.values())\n",
    "    bars = ax4.bar(periods, avg_r2, color='lightcoral', alpha=0.7)\n",
    "    ax4.set_title('Average R¬≤ by Annual Period', fontsize=12, fontweight='bold')\n",
    "    ax4.set_ylabel('Average R¬≤ Score')\n",
    "    ax4.tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Add value labels\n",
    "    for bar, value in zip(bars, avg_r2):\n",
    "        ax4.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
    "                f'{value:.3f}', ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../output/plots/yearly_factor_evolution.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Print detailed summary insights\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"ANNUAL PERIOD ANALYSIS SUMMARY (2022-2025)\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "for period, r2_scores in yearly_r2_results.items():\n",
    "    if r2_scores:\n",
    "        best_etf = max(r2_scores.items(), key=lambda x: x[1])\n",
    "        worst_etf = min(r2_scores.items(), key=lambda x: x[1])\n",
    "        avg_r2 = np.mean(list(r2_scores.values()))\n",
    "        \n",
    "        print(f\"\\n{period} Period:\")\n",
    "        print(f\"  Highest Macro Sensitivity: {best_etf[0]} (R¬≤ = {best_etf[1]:.3f})\")\n",
    "        print(f\"  Lowest Macro Sensitivity:  {worst_etf[0]} (R¬≤ = {worst_etf[1]:.3f})\")\n",
    "        print(f\"  Average R¬≤:                 {avg_r2:.3f}\")\n",
    "        print(f\"  ETFs Analyzed:              {len(r2_scores)}\")\n",
    "\n",
    "# Identify trend patterns across the three annual periods\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"TREND IDENTIFICATION ACROSS ANNUAL PERIODS\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "for etf in em_etf_columns:\n",
    "    etf_trend = []\n",
    "    periods_analyzed = []\n",
    "    for period in sorted(yearly_r2_results.keys()):\n",
    "        if etf in yearly_r2_results[period]:\n",
    "            etf_trend.append(yearly_r2_results[period][etf])\n",
    "            periods_analyzed.append(period)\n",
    "    \n",
    "    if len(etf_trend) >= 2:\n",
    "        # Calculate overall trend\n",
    "        if etf_trend[-1] > etf_trend[0]:\n",
    "            trend_direction = \"INCREASING\"\n",
    "            trend_arrow = \"‚ÜóÔ∏è\"\n",
    "        else:\n",
    "            trend_direction = \"DECREASING\"\n",
    "            trend_arrow = \"‚ÜòÔ∏è\"\n",
    "        \n",
    "        trend_magnitude = abs(etf_trend[-1] - etf_trend[0])\n",
    "        trend_volatility = np.std(etf_trend) if len(etf_trend) > 2 else 0\n",
    "        \n",
    "        print(f\"{etf}: {trend_arrow} {trend_direction} trend\")\n",
    "        print(f\"  ‚Ä¢ Magnitude: Œî = {trend_magnitude:.3f}\")\n",
    "        print(f\"  ‚Ä¢ Volatility: œÉ = {trend_volatility:.3f}\")\n",
    "        print(f\"  ‚Ä¢ Periods: {' ‚Üí '.join(periods_analyzed)}\")\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"INVESTMENT IMPLICATIONS BY PERIOD\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "# Identify period-specific characteristics\n",
    "all_periods = list(yearly_r2_results.keys())\n",
    "if len(all_periods) >= 3:\n",
    "    early_period = all_periods[0]\n",
    "    middle_period = all_periods[1] \n",
    "    recent_period = all_periods[2]\n",
    "    \n",
    "    print(f\"\\nüìä {early_period} (Post-Pandemic Recovery):\")\n",
    "    if early_period in yearly_r2_results and yearly_r2_results[early_period]:\n",
    "        early_avg = np.mean(list(yearly_r2_results[early_period].values()))\n",
    "        print(f\"  ‚Ä¢ Average Factor Sensitivity: {early_avg:.3f}\")\n",
    "        print(f\"  ‚Ä¢ Market Regime: Elevated macro sensitivity during recovery\")\n",
    "        print(f\"  ‚Ä¢ Investment Theme: Reflation trade and commodity super-cycle\")\n",
    "    \n",
    "    print(f\"\\nüìä {middle_period} (Tightening Cycle):\")\n",
    "    if middle_period in yearly_r2_results and yearly_r2_results[middle_period]:\n",
    "        middle_avg = np.mean(list(yearly_r2_results[middle_period].values()))\n",
    "        print(f\"  ‚Ä¢ Average Factor Sensitivity: {middle_avg:.3f}\")\n",
    "        print(f\"  ‚Ä¢ Market Regime: Policy divergence and geopolitical tensions\")\n",
    "        print(f\"  ‚Ä¢ Investment Theme: Differentiated EM responses to global tightening\")\n",
    "    \n",
    "    print(f\"\\nüìä {recent_period} (Normalization Phase):\")\n",
    "    if recent_period in yearly_r2_results and yearly_r2_results[recent_period]:\n",
    "        recent_avg = np.mean(list(yearly_r2_results[recent_period].values()))\n",
    "        print(f\"  ‚Ä¢ Average Factor Sensitivity: {recent_avg:.3f}\")\n",
    "        print(f\"  ‚Ä¢ Market Regime: Rate normalization and evolving factor structures\")\n",
    "        print(f\"  ‚Ä¢ Investment Theme: New equilibrium in EM-macro relationships\")\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"STRATEGIC RECOMMENDATIONS\")\n",
    "print(f\"{'='*70}\")\n",
    "print(\"üéØ Factor Strategy Insights:\")\n",
    "print(\"  ‚Ä¢ ETFs with increasing R¬≤ trends show growing macro sensitivity\")\n",
    "print(\"  ‚Ä¢ ETFs with decreasing R¬≤ trends may offer better diversification benefits\")\n",
    "print(\"  ‚Ä¢ High temporal volatility indicates regime-dependent factor exposure\")\n",
    "print(\"  ‚Ä¢ Period-specific analysis enables more precise factor timing strategies\")\n",
    "print(\"\\nüíº Portfolio Construction:\")\n",
    "print(\"  ‚Ä¢ Implement dynamic rebalancing based on rolling factor sensitivities\")\n",
    "print(\"  ‚Ä¢ Use period-specific factor loadings for tactical asset allocation\")\n",
    "print(\"  ‚Ä¢ Monitor regime changes for proactive risk management\")\n",
    "print(\"\\n‚ö†Ô∏è Risk Management:\")\n",
    "print(\"  ‚Ä¢ Update hedge ratios quarterly based on evolving factor sensitivities\")\n",
    "print(\"  ‚Ä¢ Stress test portfolios across different temporal regimes\")\n",
    "print(\"  ‚Ä¢ Track correlation evolution for improved diversification\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
